{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_data = os.listdir('./data/small_data/train')\n",
    "img_data = os.listdir('./data/small_data/train')\n",
    "\n",
    "flower_mapping = {'daisy':0, 'dandelion':1, 'rose':2, 'sunflower':3, 'tulip':4}\n",
    "\n",
    "IMAGE_DIMS = (240, 320, 3)\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "# loop over the input images\n",
    "# for imagePath in imagePaths:\n",
    "# \t# load the image, pre-process it, and store it in the data list\n",
    "# \timage = cv2.imread(imagePath)\n",
    "# \timage = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
    "# \timage = img_to_array(image)\n",
    "# \timages.append(image)\n",
    " \n",
    "# \t# extract the class label from the image path and update the\n",
    "# \t# labels list\n",
    "# \tlabel = imagePath.split(os.path.sep)[-2]\n",
    "# \tlabels.append(label)\n",
    "\n",
    "for img_dir in img_data:\n",
    "    for fn in os.listdir(os.path.join('./data/small_data/train/',img_dir)):\n",
    "        fd = os.path.join('./data/small_data/train/',img_dir,fn)\n",
    "        image = cv2.imread(fd)\n",
    "        image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
    "        image = img_to_array(image)\n",
    "        data.append(image)\n",
    "        labels.append(flower_mapping.get(img_dir))\n",
    "        \n",
    "# for img_dir in img_data:\n",
    "#     for fn in os.listdir(os.path.join('./data/image_data/train/',img_dir)):\n",
    "#         fd = os.path.join('./data/image_data/train/',img_dir,fn)\n",
    "#         image = cv2.imread(fd)\n",
    "#         image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
    "#         image = img_to_array(image)\n",
    "#         data.append(image)\n",
    "#         labels.append(flower_mapping.get(img_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 320, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data matrix: 180.00MB\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "print(\"[INFO] data matrix: {:.2f}MB\".format(\n",
    "\tdata.nbytes / (1024 * 1000.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "\tlabels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape', (80,))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-95bb29288387>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/test_py3/lib/python3.6/site-packages/keras_preprocessing/image/image_data_generator.py\u001b[0m in \u001b[0;36mflow\u001b[0;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, subset)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0msave_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         )\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test_py3/lib/python3.6/site-packages/keras_preprocessing/image/numpy_array_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001b[0m\n\u001b[1;32m    115\u001b[0m             raise ValueError('Input data in `NumpyArrayIterator` '\n\u001b[1;32m    116\u001b[0m                              \u001b[0;34m'should have rank 4. You passed an array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                              'with shape', self.x.shape)\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mchannels_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_last'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchannels_axis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ('Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape', (80,))"
     ]
    }
   ],
   "source": [
    "trainX = next(data_generator.flow(trainX, shuffle=False))\n",
    "trainY = next(data_generator.flow(trainY, shuffle=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "INIT_LR = 1e-3\n",
    "BS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(565, 240, 320, 3)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_65 (Conv2D)           (None, 240, 320, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 240, 320, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 240, 320, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 80, 106, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 80, 106, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 80, 106, 64)       18496     \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 80, 106, 64)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 80, 106, 64)       256       \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 80, 106, 64)       36928     \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 80, 106, 64)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 80, 106, 64)       256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 40, 53, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 40, 53, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 40, 53, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 40, 53, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 40, 53, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 40, 53, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 40, 53, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 40, 53, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 20, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 20, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 66560)             0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1024)              68158464  \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 5)                 5125      \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 68,447,109\n",
      "Trainable params: 68,444,229\n",
      "Non-trainable params: 2,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##V0 CNN\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "# from keras.layers import Conv2D, MaxPooling2D\n",
    "# from keras.optimizers import RMSprop, Adam\n",
    "\n",
    "# num_classes = 5\n",
    "# testY = keras.utils.to_categorical(testY, num_classes)\n",
    "# trainY = keras.utils.to_categorical(trainY, num_classes)\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(16, (5, 5), padding='same',\n",
    "#                  input_shape=trainX.shape[1:]))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(16, (5, 5)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Conv2D(32, (5, 5), padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(32, (5, 5)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(num_classes))\n",
    "# model.add(Activation('softmax'))\n",
    "# model.summary()\n",
    "\n",
    "##SmallVGGNet\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "classes = 5\n",
    "model = Sequential()\n",
    "inputShape = trainX.shape[1:]\n",
    "chanDim = -1\n",
    "testY = keras.utils.to_categorical(testY, num_classes)\n",
    "trainY = keras.utils.to_categorical(trainY, num_classes)\n",
    "inputShape = trainX.shape[1:]\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=inputShape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(64, (3,3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3,3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(128, (3,3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(classes))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2258 samples, validate on 565 samples\n",
      "Epoch 1/20\n",
      "2258/2258 [==============================] - 1445s 640ms/step - loss: 1.7634 - acc: 0.2750 - val_loss: 1.7708 - val_acc: 0.2903\n",
      "Epoch 2/20\n",
      "2258/2258 [==============================] - 1444s 640ms/step - loss: 1.5800 - acc: 0.3339 - val_loss: 1.5242 - val_acc: 0.3664\n",
      "Epoch 3/20\n",
      "2258/2258 [==============================] - 1430s 633ms/step - loss: 1.5461 - acc: 0.3299 - val_loss: 1.5198 - val_acc: 0.3965\n",
      "Epoch 4/20\n",
      "2258/2258 [==============================] - 1393s 617ms/step - loss: 1.5154 - acc: 0.3601 - val_loss: 1.4611 - val_acc: 0.4319\n",
      "Epoch 5/20\n",
      "2258/2258 [==============================] - 1435s 635ms/step - loss: 1.4839 - acc: 0.3835 - val_loss: 1.8296 - val_acc: 0.2867\n",
      "Epoch 6/20\n",
      "2258/2258 [==============================] - 1438s 637ms/step - loss: 1.5056 - acc: 0.3694 - val_loss: 1.5324 - val_acc: 0.3681\n",
      "Epoch 7/20\n",
      "2258/2258 [==============================] - 1395s 618ms/step - loss: 1.5964 - acc: 0.3273 - val_loss: 1.5851 - val_acc: 0.2885\n",
      "Epoch 8/20\n",
      "2258/2258 [==============================] - 1326s 587ms/step - loss: 1.5701 - acc: 0.3136 - val_loss: 1.5388 - val_acc: 0.3876\n",
      "Epoch 9/20\n",
      "2258/2258 [==============================] - 1365s 604ms/step - loss: 1.5740 - acc: 0.2848 - val_loss: 1.5146 - val_acc: 0.3982\n",
      "Epoch 10/20\n",
      "2258/2258 [==============================] - 1376s 609ms/step - loss: 1.5594 - acc: 0.3215 - val_loss: 2.7850 - val_acc: 0.2549\n",
      "Epoch 11/20\n",
      "2258/2258 [==============================] - 1325s 587ms/step - loss: 1.5966 - acc: 0.2914 - val_loss: 1.5575 - val_acc: 0.2903\n",
      "Epoch 12/20\n",
      "2258/2258 [==============================] - 1434s 635ms/step - loss: 1.5598 - acc: 0.3180 - val_loss: 1.4810 - val_acc: 0.3912\n",
      "Epoch 13/20\n",
      "2258/2258 [==============================] - 1434s 635ms/step - loss: 1.5050 - acc: 0.3760 - val_loss: 1.4411 - val_acc: 0.3947\n",
      "Epoch 14/20\n",
      "2258/2258 [==============================] - 1431s 634ms/step - loss: 1.4944 - acc: 0.3787 - val_loss: 1.4361 - val_acc: 0.3929\n",
      "Epoch 15/20\n",
      "2258/2258 [==============================] - 1434s 635ms/step - loss: 1.5023 - acc: 0.3946 - val_loss: 1.4550 - val_acc: 0.3947\n",
      "Epoch 16/20\n",
      "2258/2258 [==============================] - 1479s 655ms/step - loss: 1.4894 - acc: 0.3711 - val_loss: 1.4651 - val_acc: 0.4319\n",
      "Epoch 17/20\n",
      "2258/2258 [==============================] - 1450s 642ms/step - loss: 1.4736 - acc: 0.3623 - val_loss: 1.4504 - val_acc: 0.4000\n",
      "Epoch 18/20\n",
      "2258/2258 [==============================] - 1388s 615ms/step - loss: 1.4786 - acc: 0.3990 - val_loss: 1.4085 - val_acc: 0.4442\n",
      "Epoch 19/20\n",
      "2258/2258 [==============================] - 1419s 628ms/step - loss: 1.4480 - acc: 0.4154 - val_loss: 1.4523 - val_acc: 0.4230\n",
      "Epoch 20/20\n",
      "2258/2258 [==============================] - 6565s 3s/step - loss: 1.4638 - acc: 0.4052 - val_loss: 1.4706 - val_acc: 0.4230\n",
      "Test loss: 1.470601027834732\n",
      "Test accuracy: 0.42300884982125947\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(trainX, trainY,\n",
    "                    batch_size=4,\n",
    "                    epochs=EPOCHS,\n",
    "                    verbose=1,\n",
    "                    validation_data=(testX, testY))\n",
    "score = model.evaluate(testX, testY, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 320, 3)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img_data = os.listdir('./data/image_data/test')\n",
    "test_data = []\n",
    "for test_img_dir in test_img_data:\n",
    "    fd = os.path.join('./data/image_data/test/',test_img_dir)\n",
    "    image = cv2.imread(fd)\n",
    "    image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
    "    image = img_to_array(image)\n",
    "    test_data.append(image)\n",
    "test_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data matrix: 3600.00MB\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array(test_data, dtype=\"float\") / 255.0\n",
    "print(\"[INFO] data matrix: {:.2f}MB\".format(\n",
    "\ttest_data.nbytes / (1024 * 1000.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "ynew = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9970715 , 0.9978508 , 0.99999654, 0.9998927 , 1.        ],\n",
       "       [0.418367  , 0.99977905, 0.9795855 , 0.9953295 , 0.9994764 ],\n",
       "       [0.00391951, 0.05201413, 0.99974126, 0.94698113, 0.99999976],\n",
       "       ...,\n",
       "       [0.9999856 , 0.99998116, 0.03284308, 0.00807271, 0.9849975 ],\n",
       "       [0.99588263, 0.999972  , 0.9891473 , 0.9996394 , 0.9979873 ],\n",
       "       [0.97290516, 0.99966574, 0.99120456, 0.18990047, 0.94132465]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "0\n",
      "0\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "3\n",
      "0\n",
      "4\n",
      "4\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "4\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "3\n",
      "2\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "2\n",
      "0\n",
      "4\n",
      "1\n",
      "2\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "4\n",
      "0\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "0\n",
      "2\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "4\n",
      "4\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "0\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "2\n",
      "1\n",
      "4\n",
      "0\n",
      "1\n",
      "4\n",
      "0\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "4\n",
      "4\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "3\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "4\n",
      "3\n",
      "1\n",
      "0\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "4\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "0\n",
      "1\n",
      "4\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "3\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "2\n",
      "4\n",
      "0\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "2\n",
      "4\n",
      "4\n",
      "1\n",
      "3\n",
      "0\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "0\n",
      "1\n",
      "4\n",
      "0\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "0\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "2\n",
      "4\n",
      "0\n",
      "4\n",
      "4\n",
      "1\n",
      "2\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "4\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "4\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "4\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "4\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "4\n",
      "4\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "0\n",
      "1\n",
      "4\n",
      "2\n",
      "4\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "2\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "0\n",
      "1\n",
      "4\n",
      "1\n",
      "0\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "2\n",
      "3\n",
      "1\n",
      "4\n",
      "2\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "0\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "3\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "4\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "0\n",
      "4\n",
      "0\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "4\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "4\n",
      "0\n",
      "4\n",
      "2\n",
      "4\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "0\n",
      "1\n",
      "4\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "4\n",
      "0\n",
      "4\n",
      "4\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "0\n",
      "4\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "4\n",
      "0\n",
      "1\n",
      "0\n",
      "3\n",
      "1\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "0\n",
      "4\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "4\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "2\n",
      "0\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "3\n",
      "1\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "4\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "3\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "4\n",
      "0\n",
      "4\n",
      "2\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "0\n",
      "4\n",
      "4\n",
      "3\n",
      "0\n",
      "1\n",
      "4\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "4\n",
      "1\n",
      "1\n",
      "3\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "3\n",
      "1\n",
      "1\n",
      "2\n",
      "4\n",
      "0\n",
      "4\n",
      "1\n",
      "2\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "0\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "1\n",
      "4\n",
      "4\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "4\n",
      "0\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "0\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "4\n",
      "0\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "1\n",
      "0\n",
      "4\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "2\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "4\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "3\n",
      "1\n",
      "2\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "0\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "0\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "0\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "4\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "2\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "0\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "0\n",
      "0\n",
      "3\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "0\n",
      "0\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "0\n",
      "4\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "4\n",
      "0\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "0\n",
      "1\n",
      "4\n",
      "4\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "4\n",
      "1\n",
      "0\n",
      "4\n",
      "3\n",
      "1\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "0\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "4\n",
      "1\n",
      "0\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "2\n",
      "0\n",
      "1\n",
      "4\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "2\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "3\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "0\n",
      "4\n",
      "1\n",
      "2\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "2\n",
      "1\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "4\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "0\n",
      "4\n",
      "4\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "3\n",
      "4\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "4\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "4\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "3\n",
      "0\n",
      "1\n",
      "4\n",
      "4\n",
      "3\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "4\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "0\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "0\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for yn in ynew:\n",
    "    res.append(np.argmax(yn))\n",
    "for r in res:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>flower_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0028624c49b3e0610ff9f1d111f5d532</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002c30700185b7971369258b438070d5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00852f4f666acecd0c0d140365b42efd</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00c08828fce04e360c732cac01edad9e</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00d366e7877b6a78b104b57d67b60e6b</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00e803f7bc6d21b6d6d3a98136ea4635</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00e9cb1dca407810856e77b31309d5ab</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>014d33090eb706769ff782d8c500dc2a</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>015c8f0e6b95baf9dcbb34647624c5b8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0194948a29f0e891c54f88004fb4c51c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>01964126d7cc3122173ce68761cc23bd</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0279619774b01b44b05b33bff44b541f</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>027f28c9c4e255b22a8e0026cd5868b3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0290c31cfc41f2dc51dcaff0dbda2da5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>02b5b88e51b7abd559bfb95138f33b95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>02b703e9b535936aa0e00886fc4669c3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>033925568a8d3170e7d7710483e3fae6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>034d01c095f88f0bcde09c3bb96682cd</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0370dc76bacae16e2e447b6a7549f3df</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>03763fddc1b3b7e5751cc65398f28bf8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>03d2eb71b65a830092a3b6779aedbb4c</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>03dffb85cc0a231b84e6754909e37da0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>041bdb3a90ae06361c3cbc246a5c291d</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>041ce10ffd2ef73afe7e6d5fae045c98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>04335847221321fc6000797aa07093a2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>044c7523fa93b045871e457757365da1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0453b5ee36bc0b7e60194306ee410397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>048c3b5db49f963ba9b9ea42ba6b5085</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0495e5cb93952bc4a728c19e40322679</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0499d6a2951fe18d4d9ed7b5d908ca19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>fd9cac41cda00325613b362025eb9cc1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>fda6dca87a0de48f83227817e3421e20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>fda7085f5d8b6f995922b19f5aeec873</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>fdb273780ac1826aef9de8c6a2d425f4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>fdb7b04782dfc1ba1ad15107b46c31f0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>fde1d5fa8f5209108ba11252a1466e5e</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>fde6e1d8c47ccd170119a780851bb8bb</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>fe1aa56322605dc0dea8c84191b095ec</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>fe4e4bf77b6f1c6cefb7e399ac4833a2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>fe4ec31c0f202270eec87466dceaaf39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>fe584d3bcf414bf5dec83d7c20de6e2a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>fe64b09b1e78de73cc137ce86402a096</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>fe7696e49ad15f45d8e8a04165e162f0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>fe829d2d57b3363eee1126d7a93737d9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>fe95e014bee15aa951836e6e7cfad8ec</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>fea9d31e49b014ecedb876a726a990d1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>fec2f9d0632d24fb84fa8f30e7f00e1d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>fef84518e3118b231928869a6b36e94e</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>ff0dc86f342218bc603798edce886a90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>ff3806a9b55957a4e869983be698dc4a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>ff3df418b948dbbe61d45cced4260107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>ff5ed4106759efd6fc5eb97ea8babf0b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>ff60ba30933a5e6a262282696e8769d7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>ff6c8cddba2bea63f97c8f276c8321d9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>ff764f30a84d2bd0fd62444c9363abb0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>ff7eac29b6d7a33fbd8009677c3e9c58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>ffbc32a7b67dfe72b8d35d4b1b35fd6c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>ffea1f275c05accb0a6bfd1203620c7e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>ffeb2a1cf53464b6af937ab8af0c2946</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>ffefcc68e2e7eed8b17b0b5b0f740538</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id flower_class\n",
       "0     0028624c49b3e0610ff9f1d111f5d532            4\n",
       "1     002c30700185b7971369258b438070d5            1\n",
       "2     00852f4f666acecd0c0d140365b42efd            4\n",
       "3     00c08828fce04e360c732cac01edad9e            4\n",
       "4     00d366e7877b6a78b104b57d67b60e6b            4\n",
       "5     00e803f7bc6d21b6d6d3a98136ea4635            2\n",
       "6     00e9cb1dca407810856e77b31309d5ab            1\n",
       "7     014d33090eb706769ff782d8c500dc2a            4\n",
       "8     015c8f0e6b95baf9dcbb34647624c5b8            4\n",
       "9     0194948a29f0e891c54f88004fb4c51c            1\n",
       "10    01964126d7cc3122173ce68761cc23bd            4\n",
       "11    0279619774b01b44b05b33bff44b541f            1\n",
       "12    027f28c9c4e255b22a8e0026cd5868b3            4\n",
       "13    0290c31cfc41f2dc51dcaff0dbda2da5            1\n",
       "14    02b5b88e51b7abd559bfb95138f33b95            0\n",
       "15    02b703e9b535936aa0e00886fc4669c3            0\n",
       "16    033925568a8d3170e7d7710483e3fae6            4\n",
       "17    034d01c095f88f0bcde09c3bb96682cd            4\n",
       "18    0370dc76bacae16e2e447b6a7549f3df            1\n",
       "19    03763fddc1b3b7e5751cc65398f28bf8            1\n",
       "20    03d2eb71b65a830092a3b6779aedbb4c            4\n",
       "21    03dffb85cc0a231b84e6754909e37da0            4\n",
       "22    041bdb3a90ae06361c3cbc246a5c291d            4\n",
       "23    041ce10ffd2ef73afe7e6d5fae045c98            1\n",
       "24    04335847221321fc6000797aa07093a2            4\n",
       "25    044c7523fa93b045871e457757365da1            4\n",
       "26    0453b5ee36bc0b7e60194306ee410397            1\n",
       "27    048c3b5db49f963ba9b9ea42ba6b5085            4\n",
       "28    0495e5cb93952bc4a728c19e40322679            1\n",
       "29    0499d6a2951fe18d4d9ed7b5d908ca19            4\n",
       "...                                ...          ...\n",
       "1970  fd9cac41cda00325613b362025eb9cc1            4\n",
       "1971  fda6dca87a0de48f83227817e3421e20            4\n",
       "1972  fda7085f5d8b6f995922b19f5aeec873            0\n",
       "1973  fdb273780ac1826aef9de8c6a2d425f4            1\n",
       "1974  fdb7b04782dfc1ba1ad15107b46c31f0            4\n",
       "1975  fde1d5fa8f5209108ba11252a1466e5e            1\n",
       "1976  fde6e1d8c47ccd170119a780851bb8bb            4\n",
       "1977  fe1aa56322605dc0dea8c84191b095ec            4\n",
       "1978  fe4e4bf77b6f1c6cefb7e399ac4833a2            1\n",
       "1979  fe4ec31c0f202270eec87466dceaaf39            1\n",
       "1980  fe584d3bcf414bf5dec83d7c20de6e2a            2\n",
       "1981  fe64b09b1e78de73cc137ce86402a096            1\n",
       "1982  fe7696e49ad15f45d8e8a04165e162f0            1\n",
       "1983  fe829d2d57b3363eee1126d7a93737d9            0\n",
       "1984  fe95e014bee15aa951836e6e7cfad8ec            1\n",
       "1985  fea9d31e49b014ecedb876a726a990d1            1\n",
       "1986  fec2f9d0632d24fb84fa8f30e7f00e1d            1\n",
       "1987  fef84518e3118b231928869a6b36e94e            1\n",
       "1988  ff0dc86f342218bc603798edce886a90            1\n",
       "1989  ff3806a9b55957a4e869983be698dc4a            1\n",
       "1990  ff3df418b948dbbe61d45cced4260107            1\n",
       "1991  ff5ed4106759efd6fc5eb97ea8babf0b            1\n",
       "1992  ff60ba30933a5e6a262282696e8769d7            0\n",
       "1993  ff6c8cddba2bea63f97c8f276c8321d9            1\n",
       "1994  ff764f30a84d2bd0fd62444c9363abb0            0\n",
       "1995  ff7eac29b6d7a33fbd8009677c3e9c58            1\n",
       "1996  ffbc32a7b67dfe72b8d35d4b1b35fd6c            1\n",
       "1997  ffea1f275c05accb0a6bfd1203620c7e            0\n",
       "1998  ffeb2a1cf53464b6af937ab8af0c2946            1\n",
       "1999  ffefcc68e2e7eed8b17b0b5b0f740538            1\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "test_img_data = os.listdir('./data/image_data/test')\n",
    "test_id = []\n",
    "i=0\n",
    "for test_img_dir in test_img_data:\n",
    "    test_id.append([test_img_dir.split(\".\")[0],res[i]])\n",
    "    i = i +1\n",
    "\n",
    "np_ids= np.array(test_id)\n",
    "test_ids = pd.DataFrame(np_ids)\n",
    "test_ids.columns = ['id', 'flower_class']\n",
    "test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data = './'\n",
    "test_ids.to_csv(dir_data+'final_ans.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
